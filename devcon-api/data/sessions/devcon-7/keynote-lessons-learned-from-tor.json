{
  "id": "keynote-lessons-learned-from-tor",
  "sourceId": "ZHU7UQ",
  "title": "Keynote: Lessons learned from Tor",
  "description": "I will share lessons learned during Tor's twenty years as free software fighting for privacy and human rights. We'll talk about distributed trust and privacy by design, how to help people understand the good uses of your tech, getting allies in both cypherpunks and government, why transparency and community-building are so essential to trust, and successes from other spaces. It may seem like the crypto wars never really end, but we all have a part to play in saving the world.",
  "track": "Cypherpunk & Privacy",
  "type": "Talk",
  "expertise": "Intermediate",
  "audience": "Engineering",
  "featured": true,
  "doNotRecord": false,
  "tags": [
    "Anonymity",
    "Privacy",
    "Sustainability"
  ],
  "keywords": [
    "Human",
    "rights"
  ],
  "duration": 1911,
  "language": "en",
  "sources_swarmHash": "bc74f4b9d585e354aacc1ead7ee0dec2d4b065e411877d110f120117979ff52f",
  "sources_youtubeId": "o302oKXbdK8",
  "sources_ipfsHash": "",
  "sources_livepeerId": "",
  "sources_streamethId": "673811671b0f83434dc79ca7",
  "transcript_vtt": "https://streameth-develop.ams3.digitaloceanspaces.com/transcriptions/673811671b0f83434dc79ca7.vtt",
  "transcript_text": " The microphone is working. The slides seem like they're working. I hope we'll find out soon if they're... I'm going to press the forward button. Okay, I see them over here. That means that they will appear pretty soon. So, hi, I'm Roger Dingledine from the Tor Project. Once upon a time, I started a non-profit called Tor and wrote the original code, so there's a lot to talk about today. I'm going to break this down into two pieces. The first piece is giving you a crash course on Tor and things to think about, and then the second piece is advice and lessons for the Ethereum and cryptocurrency communities from what we've learned over the past many years. So Tor is a lot of different things. It's a free software project, open source project that you learned about from the last speaker. It's also a bunch of different projects, each trying to provide privacy in various ways. It's a non-profit as I mentioned and the fun part about Tor is the global community of people all around the world who use it and rely on it and help to make it stronger and better. So many people use Tor in the form of Tor Browser which is a Firefox based browser that fixes a bunch of application level issues. So there's the underlying program Tor but the interface that most people see is Tor browser. Okay, so what am I talking about here in terms of privacy? I talk about privacy and security, but really the phrase is communications metadata. It's the idea that I want to browse the web and I want somebody watching my internet connection to not learn what destination I'm going to. And I want the website to be able to not learn where I'm coming from. So how many people here recognize Creepy NSA Dude from back in the Snowden times? So he helped to run the intelligence system for the US government and he has this scary, terrible quote, we kill people based on metadata. And the important thing here is nobody in the attacker world these days is trying to break the encryption anymore. The encryption works well. Instead, let's build a social graph of who's talking to who, when they're talking, how much they're talking, and then we'll look for who's talking to who, when they're talking, how much they're talking, and then we'll look for who's in the middle of that graph, and then we break into their house and steal their laptop or whatever attack we have to do from there. And there are a bunch of other current events that are related to all of this. Here's a news story from, I guess, five years ago now. The U.S. Attorney General asks Facebook to stop doing end-to-end encryption for their messenger. And there's this terrible quote from the request. We're writing a request that Facebook does not proceed with its plan to implement end-to-end encryption without ensuring there is no reduction to user safety. That drives me nuts. Imagine if they said, we're writing to request that Facebook not implement HTTPS without ensuring that there is no reduction to user safety. That would be an unbelievable thing for them to say, but here they are saying it. And then fast forward four years, we still have the same arguments going on where England is saying, but if you allow your users to have control over their own information, society will collapse, everybody will become criminals, we'll never be able to track everything. And another example from earlier this year, apparently in the US, law enforcement sent a YouTube video URL to somebody they were trying to attack and then they went to YouTube and said, tell us everybody who watched that video. And I don't know if YouTube actually answered them but that's the future of law enforcement where you make use of the huge platforms that collaborate with governments and that's it for your privacy. So I'd like to live in a world instead where people, individuals have control over who gets to learn about them. And then the final example that happened a couple of years ago, apparently there was somebody in the US state of Nebraska who wanted an abortion and talked to her mother on Facebook Messenger about whether she should get an abortion and now she's being prosecuted for conspiracy to want an abortion and that's the country that I live in now. So that's another case where privacy, the ability to have conversations of things that should be legal, is something that the world needs to keep. Okay, so I actually only use the word anonymity when I'm talking to researchers. When I'm talking to my parents, I tell them I'm working on a privacy system, because anonymity, I don't know who needs that but privacy is an important value for everybody. And then when I'm talking to Walmart and Google and other companies, I work on communication security because privacy is dead, says the Oracle guy, anonymity is confusing. But of course we need to protect somebody from learning who our suppliers are, what we're investigating on the internet. When Goldman Sachs is thinking about stocks to invest in, of course they don't want their competitors watching their internet traffic to learn what research they're doing. And then from the government side, it's the same tools, but for governments I explain that I work on traffic analysis resistant communication networks. And again, it's the same security properties, but it's about figuring out how to phrase it for those groups. And then there's a fourth category, which we can talk about in this country, but maybe not some countries nearby here on the human rights side, where there are people who can't reach bbc.com and they want to be able to read the news or share news. Okay, so how do you build one of these? The easy answer is you have some centralized system like a VPN and all of the users connect and ask for a web page. And that's great, except what about that central point of failure? So imagine that really in the middle. It always starts off with, we're never going to look at any of your traffic. Don't worry. We promise to keep you safe. Okay, actually, we do look at all of your traffic, but don't worry, we won't write it down. Okay, actually, we do log everything, but don't worry, we won't tell other people. Okay, well, of course, we answer governments, but don't worry, we won't tell other people. And I don't know where the next step after that is. The problem there is you can't tell. It's a centralized system. You don't know what they're going to do with your data. They have your data. They promise not to screw you. That's not good enough. And it's even worse than that. Even if that centralized system is somehow perfectly honest and really does want to keep you safe, it's still one computer somewhere. All the traffic goes in, the same traffic goes out, and if you're good at math, maybe you can match up this data flow coming in matches that data flow going out, so this user did that. So even if the VPN provider is totally honest and perfectly secure for all definitions of that, the fact that it's a centralized service is itself still a danger if there's some sort of network level adversary that gets to watch things. So the goal of Tor is to distribute the trust to decentralize over multiple relays so there's no single point that gets to know this user is going to that destination. So it's no longer about privacy by promise. It's no longer about, I have the data, I promise I will keep you safe. Now it's about privacy by design, where the architecture of the system means there's no place that knows what you're doing on it. So that's the summary of Tor's goals and threat models. In terms of the network over time, we have about 8,000 relays around the world. Here's a graph of the the load on the network and the capacity of the network over time. So we're continuing to grow. The fun part of this is that if you look at the Wikipedia bandwidth graph, it looks like this just five or ten years behind. So we're continuing to go up as Wikipedia did back then. Okay, so how do you actually think about security for Tor? There are two big answers for that. One of them is the diversity of where the relays are around the world. So as we add more rel the relays are around the world. So as we add more relays in different places around the world it becomes harder for a given attacker to be able to see the traffic going into the Tor network and the corresponding traffic coming out. And then the second one that's a bit more hard to quantify is diversity of types of users. So we have a lot of users in Iran. They're not all political dissidents. Most of them are using Tor because Iran blocked Facebook and they can't read their pictures of kittens on the blogs that they want to look at. And that ordinariness is really important for security. If everybody using Tor in Iran were trying to tear down their government right now, then the fact that you're using Tor would itself be dangerous. So we need a whole lot of ordinary people in order to provide protection for all of the higher value users out there also. Okay, so I talked before about the network level privacy, hiding your IP address, where you're coming from, where you're going. But there's a second piece that you have to do in Tor, which is the application level privacy. So we have Tor browser and it fixes a bunch of browser layer things like cookies, what version of JavaScript, what languages you prefer, how many pixels by how many pixels your browser window is, all of these ways that websites can recognize you. Even if Tor is doing its job, they can still say, oh, that's the guy running on Mac OS who prefers Thai, but Korean will be okay. So there are two different pieces to what we need to do for safety. And Tor browser actually tries to keep you safe in a way that there are all these new private browsing modes and so on out there, which are, I mean, they sound great. But DuckDuckGo did a study a few years ago looking at what users actually think private browsing mode does. And most of them misunderstand. So private browsing mode protects against somebody looking at your hard drive after you've been browsing for a while. It browsing mode protects against somebody looking at your hard drive after you've been browsing for a while. It doesn't protect against somebody on the network watching you. It doesn't protect against the website. It doesn't protect against an advertising company tracking everything you do. So a lot of users thought private browsing mode is basically what Tor browser provides. It should actually protect you against advertisers, websites, ISPs, telephone companies, intelligence agencies, and so on. So here's, I found this fun comic explaining the private browsing mode world. So we've got the huge Chrome saying, which website would you like to see? And we've got our sad user saying, I don't want you to know. And then Chrome puts on a sock puppet and says, how about you tell the hand? And then the user's like, okay, great, yes, now you've reassured me about your privacy. So I want something that's more than just a centralized situation where they promise not to screw you, but actually they're still getting all the data. Okay, so transparency is really important for Tor. Of course we're open source. Of course we're free software. Of course we have public design documents and specifications that describe what we tried to build. And of course we are publicly identified. Hi, I'm Roger. I wrote Tor. And the goal of that is to build a community of people who can trust us. It isn't just about put the code on some website and magically people will believe us. It's about growing a community of people around the world who have met us and argued with us and thought about whether we should do things differently and collaborated. And part of the challenge there is I always talk to some security person who says, oh, ha, ha, the privacy people are talking about transparency. That's so stupid. It's not a contradiction. You can get both. Privacy is about choice. Privacy is about being able to choose who learns things about you. So because I have privacy, I can choose to be transparent and say, hi, I'm Roger, this is what I built. Okay, so that was the crash course on Tor. Now let me talk about some lessons learned from the Tor world that might apply to projects you're working on. So, the first one, make allies, make allies even among your adversaries. So, yes, you need to have good uses and you need to publicize those good uses. So this is for the people who were here two talks ago, don't be tornado cash, figure out how to tell the world about your good uses and maybe that means in your case not just having people who agree with you in the law enforcement groups that might be wondering if you should stay legal but also get users in those places so that they understand why your tool is important and needs to keep existing. So we asked people for user stories about Tor a while ago and here's two. I'm a political activist, part of a semi-criminalized minority. In my younger years, I entered the public debate openly only by anonymizing means among which Tor is key, can I get my message out without having police come to check my papers. Tor allows me freedom to publish my message to the world without being personally persecuted for it. So we have a lot of activists and journalists around the world who have this sort of story. Or I'm a doctor in a very political town. You can imagine Washington DC or Brussels. I have patients who work in legislation where billions of dollars are being spent. When I have to do research on diseases and treatments for my senators, of course I'm going to use Tor. Because I know that somebody is going to want to learn about the information, the medical information about the senators that I treat. And the same story also happens on the legal side where, yes, you're supposed to have client attorney privilege, but the reality is that you need to use technical mechanisms to secure your communication. You can't rely on the U.S. government promising not to listen in on your phone call with your lawyer. Over and over we see cases where it turns out they do listen in. And we've also had some other high-profile users over the years. Happy to talk afterwards about the whistleblowing side of Tor. But the bigger picture there is technology isn't neutral. Looking at this in terms of power imbalances, if you already have power, you don't need Tor as much. You've got a military, you've got law enforcement, you've got the laws, you've got other options. Whereas if you're a minority dissident in Myanmar, you don't have other options. Whereas if you're a minority dissident in Myanmar you don't have other options. So technology is inherently political. Think through what the changes are that you want to make in the world and make sure that the architecture and the projects that you're working on will steer towards those changes. Otherwise you'll just accidentally recreate the existing power structures of centralization and government control and things like that. And a couple of other fun, weird stories in that direction. I had a friend who was in the hacker community and he went and joined the FBI. And he understood Tor. So I had a person inside the FBI who was a Tor ally. And he was telling me a story of being in a Department of Justice meeting where they said, you know what we should do today? We should make a law outlawing Tor. And he got to stand up, because he was in that meeting, and say, excuse me, are you trying to make my job impossible? I work for the FBI and I need Tor. So having him in that room meant that they didn't try to undermine my project that day. So we need a lot of people, not just who understand Tor, but who use it and rely on it in each of these cases. Okay, lesson two, how do you build a sustainable community? So in the Tor case, we approach it with organic growth and the fundamental building block that we have is altruism. It's people who have extra resources, bandwidth, computer connections, they're at a university or an ISP or a company, and bandwidth is essentially free for them, so they contribute that back to the Tor network. Or you could imagine the financial incentives world, where the building block is capitalism. You want to bring people in who are trying to maximize the revenue that they get out of participating. And there are some challenges on the capitalism side. Let's say that we built an alternative tour network where everybody's here to maximize their revenue. In that case, shouldn't you minimize your costs? And everybody should go to the same hosting provider in Germany that's cheapest. And that would be a tendency towards re-centralization. Or if you're in it for the money, why don't you sell the user data on the side? Make an extra buck, maximize your cost even more. So it's not just different ways to build a community that end up in the same destination. You get different properties of your network. Scalability might be better on the capitalism side, but attention to user privacy, I think, is better on the altruism, organic growth side. So it depends what you want out of your system. And I want to be really cognizant here. I don't want to show up and be like capitalism is inappropriate in every situation though there is a part of me that does want to say that. But part of the lesson here is think through what you want out of your network and make sure that you're building a community that has the values that are most important for you. And in my case, the thing that's most important is making sure that the users will remain safe against whatever attackers they might worry about. Okay, so that said, there are a bunch of other incentive approaches which can potentially be helpful. So gamification, badges, building community, making things fun like that, leaderboards, and community building of having meetups. Like at various hacker conferences, we have relay operator meetups and a bunch of people who do contribute talk to each other, share notes, meet each other. And it turns out that if somebody tries to get them to take down the relay, they feel like they're part of a community and they feel like they're letting their friends down if they decide to turn off the relay. And another piece of that is there are non-profits all around the world who get together and run tour exit relays in their community. There's one in France, there's one in the Netherlands, there's one in France, there's one in the Netherlands, there's one in Sweden, there are like three in Germany, two in Canada, several in the US. And the goal of that is, first of all, you have a non-profit that's actually running the relays, but also you can put all the donations together and get more economies of scale, better bandwidth, better ISPs and so on. And there are some other options that we don't do now but maybe we should. One of them would be maybe I don't want relay operators who are trying to maximize their revenue but maybe we could still take donations and subsidize their costs. So they're not profiting, it just costs them less to do the thing that I want them to do anyway. So that would be an example that doesn't ruin the incentive structure not profiting, it just costs them less to do the thing that I want them to do anyway. So that would be an example that doesn't ruin the incentive structure but would still be helpful for growing the community. And there are some other examples like maybe if you run a relay you get faster tour which has some problems that I will talk about afterwards. So the bigger picture here, consider your ground truth. So if you're trying to build in the economics world it's called mechanism design, you folks might call it smart contracts, but if you're trying to structure a situation to steer people the way you want to steer them, think about what you can actually verify. How are you going to verify that the operators are doing the thing that you want them to do? So for example if you're trying to incentivize bandwidth, if you're paying people based on how much bandwidth their relay provides in the current tour design relays basically self advertise how much bandwidth they've got and that's fine because they don't get paid for claiming a larger number but if we naively just set up a thing saying, oh, you're providing a big number, here's your big check, then there would be new opportunities for gaming and lying, and we would end up with a weird arms race where the community is lying to us about what they're doing. Or another example, let's say we want to pay people more if they're not all running at the same ISP in Germany. So we want to incentivize based on location around the world. How do you actually know where the relays are? So here's a fun example of somebody in, I think, Sweden set up a relay and he hacked all the GOIP databases in the world and listed himself as being in Antarctica. And he did it because it was funny. Great. I agree. It's funny. Imagine if we paid him more by saying, whoa, that's a really diverse location. The GOIP databases in the world are not robust. They're not secure to gaming. They're just people who are trying to help out on locating things. So that's an example where your ground truth doesn't actually enable you to do the things you want. So another lesson three, be critical infrastructure. Have other projects rely on you in a way that they need you to stick around. So Brave bundles Tor. We have a bunch of private messaging tools and whistleblowing tools and operating systems. New York Times has an Onion address, BBC, Deutsche Welle and so on. And there's a whole ecosystem of pluggable transports for transforming your Tor traffic in a way that makes it harder to censor, that are reused and reusable by VPN companies and so on to let their users go through censoring firewalls. And another fun bizarre example, more than half of the nodes in the Bitcoin network are reachable as Tor onion addresses. So the Bitcoin network relies on the Tor network for their connectivity, reachability, privacy, and so on. And if you know the people in the Bitcoin world who made this choice, please introduce them to me. And not just the Bitcoin world, there's also the Ethereum world. We have been talking a lot with the Funding the Commons people about how to have alternative ways of sustaining the open source community. And there are a bunch of hardware wallets. Shout out to Trezor. And we did an NFT a while ago, shout out to Trezor, and we did an NFT a while ago, shout out to PleaserDAO. And here we are at DEVCON in the cypherpunks track, so there's a lot of overlapping values here already in terms of people wanting privacy, people caring about decentralization, so there's a lot of overlap there. And then the fourth lesson, learn from past wins. So that HTTPS example that I talked about before, just 10 or 15 years ago, HTTPS was not pervasive. I was arguing with Google that they should turn on HTTPS for their websites. And they said, well, we can't allow encryption by default because schools would block us. Schools want to be able to spy on their students and learn what searches they're doing, so we can't allow encryption. And now, 10 years later, it's normal. Of course you would never go to a website without HTTPS. So we won that somehow, and it became pervasive. It became normal around the world. So how do we do that again? So the next phase that we have is these end-to-end messaging, the WhatsApps of the world, the signals of the world, where there are real adversaries trying to make it only criminals would want privacy on the internet. So it's all part of the bigger crypto, cryptography wars of whether people around the world should have control over their own information and they get to decide who gets to learn what they're doing on the internet. And this is especially challenging because US and England and Australia are the ones yelling, encryption is scary, society will collapse. And then when their foreign ministry goes to China and says, you're a dictator, stop doing that, China is like, look, I'm saying the same thing you're saying, you're scared of encryption, I'm scared of encryption. So there's a real challenge where we, this audience, need to somehow teach our governments and our legal people why encryption should be a basic human right. And there's some weird stuff going on there. Apple is on our side for this round. Facebook is on our side for this round. And that's because they know their customers actually want privacy. So there's something we can leverage here. And then a couple of last thoughts before we get to the Q&A, which I think we're ready for. EFF, Electronic Frontier Foundation, is running a campaign to get tour relays running in universities all around the world. And they'll give you an awesome challenge coin if you do it. So if you're connected to a university, please chat with me afterwards. I'd love to get you involved in that. Okay, and then last thoughts as we begin the Q&A. Consider what kind of incentives will lead to the network you want. Make allies, make sure to teach them about the importance of encryption, privacy, freedom around the world. Please join the Tor network as a relay or a bridge or a snowflake. If you don't know what those mean, happy to chat with you afterwards. But please help out in providing privacy to people all around the world. And yes, we're a nonprofit and I'd be happy to get your donations in whatever cryptocurrency you would like to provide. Thank you. Thank you so much for that, Roger. A little reminder that our privacy should be ours to choose. Now to get straight into the questions, what were the most challenging legal obstacles you encountered throughout Tor's history? Have any of them ever caused you to wake up in a cold sweat at night? Yeah. What a great question. So a lot of it, originally, we started out working with some government people, and soon after that, we were funded by EFF, Electronic Frontier Foundation, and they wanted us to exist as a demonstration of a good example of privacy. So if there were a lawsuit happening, like the Tornado Cache 1 now, they could say, look, you can't just make all this stuff illegal because Tor is one of those things and it exists, it already exists, you can't just get rid of it in the world. So I think in terms of the most challenging legal obstacles, I don't want to say that we've had a smooth ride, but we've worked really hard to try to make sure that everybody knows about the good uses of Tor, and I think that's a really important piece of it, which is challenging because there are governments out there trying to scare people about privacy and say only criminals need to have curtains on their walls, so we need to keep fighting on that one. Have any of them caused you to wake up in a cold sweat at night? Probably not the legal obstacles. How do we scale this thing? How do we keep communities going? How do we actually provide good safety, even in the face of governments trying to attack it or some jerk in Russia trying to tear it apart? So technically, more than legally. All right. theoretically more than legally. Is it possible to track a user's Tor activity by running a significant number of Tor nodes? Does this actually happen in practice? Theoretically, yes. If you run enough of the network, then it should be possible to match up the math looking at flows coming in and flows going out. Does it happen in practice? Not that we know of. We actually know a lot of the people who run the relays around the world. They're part of the relay associations that I talked about earlier. But that said, so that's the good news. Probably people are not successfully attacking the Tor network by running a lot of relays. If you've heard rumors like, I heard the FBI runs half the Tor network, that's garbage. We know the people running half the Tor network, they're not FBI. That's the good news. The bad news is the internet is too centralized. There are not very many cables going across the oceans. There are not very many web servers like Cloudflare and Akamai. So everything, there are not very many telephone companies. Most of the internet runs in Northern Europe. So there's too much centralization there in general. And that limits how much privacy we can actually provide on the internet. If you gave me a more decentralized internet, I could build you a stronger, safer Tor. All right. How can Ethereum help Tor? Yes. So one answer is we're a non-profit. We'd love to have your donations. That's the easy answer. Another answer is we need the world to understand why tools like this can be used for good. So you're in the same fight with the Tornado Cash situation, trying to figure out how do I explain the value of these things. And you've got some bad people using it. And similarly, Tor has something like 8 million daily users, including some jerk in Russia trying to do whatever they're doing. So how do we win the next round of crypto wars and help the whole world understand the importance of these things while at the same time Hollywood is making a new story about a new movie about a new movie about some dude in a hoodie and only bad people need privacy. So I think one of the big answers is we're in the same fight for the next crypto wars. All right we are out of time but maybe we can squeeze in this last one. Is it safe to run a Tor exit node? What are the potential security and legal issues? Yes so many people run Tor exit relays all are the potential security and legal issues on that? Yes, so many people run Tor exit relays all around the world and in almost every situation it is legal to do so. There are legal safe harbors that make you in the same category as the telephone companies. So legally it's actually pretty straightforward. You're all set. The challenge is your relationship with your ISP because you run a tour exit relay. Eventually, somebody sends an abuse complaint and your ISP says, oh my God, what's that? And that's your point where you have to communicate with them and have that relationship built so that people, so that they understand what you're doing. So it's not a legal question. It's about finding an ISP that agrees with you that this is important. All right. Thank you so much, Roger. Can we get a round of applause for Roger, please? Yeah. And I will be around. I'll be around to answer your questions for as long as you have them. I think there's nothing happening right here, so I'll do it here. Eventually, we'll go out there, ask your questions as long as you've got them. Thank you.",
  "eventId": "devcon-7",
  "slot_start": 1731651600000,
  "slot_end": 1731653700000,
  "slot_roomId": "main-stage",
  "resources_presentation": "https://docs.google.com/presentation/d/1kL3YxEdhVaztgX9zv7TsWTOPmhhTZ7zGvjBwWKxc__E",
  "resources_slides": "https://api.devcon.org/data/slides/devcon-7/keynote-lessons-learned-from-tor.pdf",
  "speakers": [
    "roger-dingledine"
  ]
}